from sentence_transformers import SentenceTransformer
import os
import torch
import numpy as np

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

DEFAULT_MODEL_NAME = "dangvantuan/sentence-camembert-large"
MODELS_DIR = "./models"

def get_latest_model_path():
    """
    Renvoie le chemin du mod√®le versionn√© le plus r√©cent dans ./models,
    ou DEFAULT_MODEL_NAME si aucun mod√®le local n‚Äôest trouv√©.
    """
    if not os.path.exists(MODELS_DIR):
        return DEFAULT_MODEL_NAME

    versions = [d for d in os.listdir(MODELS_DIR) if os.path.isdir(os.path.join(MODELS_DIR, d)) and d.startswith("esti-rag-ft-v")]
    if not versions:
        return DEFAULT_MODEL_NAME

    # Trier par num√©ro de version d√©croissant
    versions.sort(key=lambda v: int(v.split("-v")[-1]), reverse=True)
    return os.path.join(MODELS_DIR, versions[0])

# Chargement du mod√®le SentenceTransformer
MODEL_PATH = get_latest_model_path()
print(f"üì¶ Utilisation du mod√®le : {MODEL_PATH}")
model = SentenceTransformer(MODEL_PATH, device=DEVICE)

def get_embedding(texts):
    model_path = get_latest_model_path()
    print(f"üß† Chargement SentenceTransformer depuis : {model_path}")
    model = SentenceTransformer(model_path, device=DEVICE)
    return model.encode(texts, convert_to_numpy=True, normalize_embeddings=True)